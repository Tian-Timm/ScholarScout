import streamlit as st
import pandas as pd
import datetime
import os
import subprocess
import sys

# === Playwright Installation for Streamlit Cloud ===
@st.cache_resource
def install_playwright_browsers():
    print("â¬‡ï¸ Installing Playwright browsers...")
    try:
        subprocess.run([sys.executable, "-m", "playwright", "install", "chromium"], check=True)
        print("âœ… Playwright browsers installed.")
    except Exception as e:
        print(f"âŒ Failed to install Playwright browsers: {e}")

# Run installation once
install_playwright_browsers()

# å¼•å…¥ä½ çš„åç«¯å‡½æ•°
from main import process_faculty_url 

# === 0. å¤šè¯­è¨€é…ç½® (Localization) ===
LANG = {
    "English": {
        "title": "ğŸ“ ScholarScout: Faculty Research Extractor",
        "sidebar_config": "âš™ï¸ Configuration",
        "api_keys": "ğŸ”‘ API Credentials",
        "api_expander": "API Keys Configuration",
        "api_info": "These keys are required to run the scraper. They are not stored permanently.",
        "deepseek_label": "DeepSeek API Key (Required)",
        "s2_label": "Semantic Scholar API Key (Optional)",
        "target_url": "Target URL",
        "target_url_help": "Enter the URL of the faculty directory page.",
        "uni_name": "University Name",
        "uni_name_help": "Enter the full name of the university for verification.",
        "start_btn": "ğŸš€ Start Scraping",
        "error_api": "âŒ DeepSeek API Key is required! Please enter it in the sidebar.",
        "error_fields": "âŒ Please fill in both Target URL and University Name!",
        "status_working": "ğŸ•µï¸ ScholarScout is working...",
        "status_init": "1ï¸âƒ£ Initializing scraper...",
        "status_scraping": "2ï¸âƒ£ Scraping from: {}",
        "status_processing": "3ï¸âƒ£ Received {} records. Processing...",
        "status_empty": "âš ï¸ No faculty members found.",
        "status_reading": "3ï¸âƒ£ Reading generated file...",
        "status_complete": "âœ… Mission Complete!",
        "status_failed": "âŒ Execution Failed",
        "save_msg": "ğŸ’¾ Saving temporary file: {}...",
        "metrics_total": "Total Faculty",
        "metrics_s2": "S2 Verified",
        "metrics_web": "Web/Other",
        "data_preview": "ğŸ“Š Data Preview",
        "download_btn": "ğŸ“¥ Download Excel Report",
    },
    "ä¸­æ–‡": {
        "title": "ğŸ“ ScholarScout: æ•™æˆç§‘ç ”æ–¹å‘æå–å·¥å…·",
        "sidebar_config": "âš™ï¸ é…ç½®é€‰é¡¹",
        "api_keys": "ğŸ”‘ API å‡­è¯",
        "api_expander": "API Key é…ç½®",
        "api_info": "è¿è¡Œçˆ¬è™«éœ€è¦ API Keyï¼Œå®ƒä»¬ä»…ä¸´æ—¶ä½¿ç”¨ï¼Œä¸ä¼šè¢«æ°¸ä¹…ä¿å­˜ã€‚",
        "deepseek_label": "DeepSeek API Key (å¿…å¡«)",
        "s2_label": "Semantic Scholar API Key (é€‰å¡«)",
        "target_url": "ç›®æ ‡ç½‘å€ (Target URL)",
        "target_url_help": "è¾“å…¥å­¦é™¢æ•™èŒäººå‘˜åˆ—è¡¨é¡µé¢çš„ç½‘å€ã€‚",
        "uni_name": "å¤§å­¦å…¨å (University Name)",
        "uni_name_help": "è¾“å…¥å¤§å­¦è‹±æ–‡å…¨åï¼Œç”¨äºå­¦æœ¯æ•°æ®åº“æ ¸éªŒã€‚",
        "start_btn": "ğŸš€ å¼€å§‹é‡‡é›†",
        "error_api": "âŒ å¿…é¡»å¡«å†™ DeepSeek API Keyï¼è¯·åœ¨ä¾§è¾¹æ è¾“å…¥ã€‚",
        "error_fields": "âŒ è¯·åŒæ—¶å¡«å†™ç›®æ ‡ç½‘å€å’Œå¤§å­¦åç§°ï¼",
        "status_working": "ğŸ•µï¸ ScholarScout æ­£åœ¨è¿è¡Œ...",
        "status_init": "1ï¸âƒ£ æ­£åœ¨åˆå§‹åŒ–çˆ¬è™«...",
        "status_scraping": "2ï¸âƒ£ æ­£åœ¨æŠ“å–: {}...",
        "status_processing": "3ï¸âƒ£ å·²è·å– {} æ¡è®°å½•ï¼Œæ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†æ...",
        "status_empty": "âš ï¸ æœªæ‰¾åˆ°ä»»ä½•æ•™èŒäººå‘˜ã€‚",
        "status_reading": "3ï¸âƒ£ æ­£åœ¨è¯»å–ç”Ÿæˆçš„æ–‡ä»¶...",
        "status_complete": "âœ… ä»»åŠ¡å®Œæˆï¼",
        "status_failed": "âŒ æ‰§è¡Œå¤±è´¥",
        "save_msg": "ğŸ’¾ æ­£åœ¨ä¿å­˜ä¸´æ—¶æ–‡ä»¶: {}...",
        "metrics_total": "æ•™å¸ˆæ€»æ•°",
        "metrics_s2": "å­¦æœ¯åº“éªŒè¯",
        "metrics_web": "ç½‘é¡µæå–",
        "data_preview": "ğŸ“Š æ•°æ®é¢„è§ˆ",
        "download_btn": "ğŸ“¥ ä¸‹è½½ Excel æŠ¥å‘Š",
    }
}

# === 1. é¡µé¢åŸºç¡€é…ç½® ===
st.set_page_config(
    page_title="ScholarScout Dashboard",
    page_icon="ğŸ“",
    layout="wide"
)

# è¯­è¨€é€‰æ‹©å™¨æ”¾åœ¨ä¾§è¾¹æ æœ€ä¸Šæ–¹
with st.sidebar:
    selected_lang = st.radio("Language / è¯­è¨€", ["English", "ä¸­æ–‡"])
    T = LANG[selected_lang]

st.title(T["title"])

# === 2. ä¾§è¾¹æ é…ç½® (ç»§ç»­) ===
with st.sidebar:
    st.header(T["api_keys"])
    
    with st.expander(T["api_expander"], expanded=True):
        st.info(T["api_info"])
        
        deepseek_key = st.text_input(
            T["deepseek_label"],
            type="password",
            help="Get it from https://platform.deepseek.com/",
            placeholder="sk-..."
        )
        
        s2_key = st.text_input(
            T["s2_label"],
            type="password",
            help="Get it from https://www.semanticscholar.org/product/api.",
            placeholder="Optional"
        )

    st.divider()

    st.header(T["sidebar_config"])
    with st.form("config_form"):
        target_url = st.text_input(
            T["target_url"], 
            placeholder="https://hci.cs.wisc.edu/",
            help=T["target_url_help"]
        )
        uni_name = st.text_input(
            T["uni_name"], 
            placeholder="University of Wisconsin-Madison",
            help=T["uni_name_help"]
        )
        submitted = st.form_submit_button(T["start_btn"])

# === 3. æ ¸å¿ƒé€»è¾‘ ===
# åˆå§‹åŒ–çŠ¶æ€
if 'df_result' not in st.session_state:
    st.session_state.df_result = None
if 'csv_path' not in st.session_state:
    st.session_state.csv_path = None

if submitted:
    # 0. éªŒè¯ API Key
    if not deepseek_key:
        st.error(T["error_api"])
    elif not target_url or not uni_name:
        st.error(T["error_fields"])
    else:
        # è®¾ç½®ç¯å¢ƒå˜é‡ä¾›åç«¯ä½¿ç”¨
        os.environ["DEEPSEEK_API_KEY"] = deepseek_key
        if s2_key:
            os.environ["S2_API_KEY"] = s2_key
        # æ¸…é™¤å¯èƒ½å­˜åœ¨çš„æ—§ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœç”¨æˆ·æ¸…ç©ºäº†è¾“å…¥æ¡†ï¼‰
        elif "S2_API_KEY" in os.environ:
            del os.environ["S2_API_KEY"]

        # é‡ç½®çŠ¶æ€
        st.session_state.df_result = None
        st.session_state.csv_path = None
        
        with st.status(T["status_working"], expanded=True) as status:
            try:
                st.write(T["status_init"])
                st.write(T["status_scraping"].format(uni_name))
                
                # --- è°ƒç”¨åç«¯ (ä¼ é€’è¯­è¨€å‚æ•°) ---
                # è¿™é‡Œçš„ result æå¤§æ¦‚ç‡æ˜¯ä¸€ä¸ª List (åˆ—è¡¨)
                # Pass 'en' for English, 'zh' for Chinese
                lang_code = "en" if selected_lang == "English" else "zh"
                result = process_faculty_url(target_url, uni_name, language=lang_code)
                
                final_df = None
                final_filename = ""

                # === ğŸš‘ æ™ºèƒ½å¤„ç†é€»è¾‘ (ä¿®å¤æ ¸å¿ƒ) ===
                
                # æƒ…å†µ A: åç«¯ç›´æ¥è¿”å›äº†æ•°æ®åˆ—è¡¨ (ä½ çš„ç°çŠ¶)
                if isinstance(result, list):
                    st.write(T["status_processing"].format(len(result)))
                    
                    if not result:
                        st.warning(T["status_empty"])
                        status.update(label="âš ï¸ Finished but empty", state="error")
                    else:
                        # 1. æŠŠåˆ—è¡¨è½¬ä¸º DataFrame
                        final_df = pd.DataFrame(result)
                        
                        # 2. å‰ç«¯è‡ªå·±ç”Ÿæˆæ–‡ä»¶å
                        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M")
                        safe_uni_name = "".join([c if c.isalnum() else "_" for c in uni_name])
                        final_filename = f"{safe_uni_name}_{timestamp}.xlsx"
                        
                        # 3. ä¿å­˜æ–‡ä»¶ (ä»¥ä¾¿ä¸‹è½½)
                        st.write(T["save_msg"].format(final_filename))
                        final_df.to_excel(final_filename, index=False)
                
                # æƒ…å†µ B: åç«¯è¿”å›äº†æ–‡ä»¶å (ä»¥é˜²ä¸‡ä¸€ä½ ä»¥åæ”¹äº†åç«¯)
                elif isinstance(result, str):
                    st.write(T["status_reading"])
                    final_filename = result
                    final_df = pd.read_excel(result)
                
                else:
                    st.error(f"Unknown return type: {type(result)}")

                # === å¤„ç†å®Œæˆ ===
                
                if final_df is not None and not final_df.empty:
                    # æ›´æ–° Session Stateï¼Œå¼ºåˆ¶åˆ·æ–°é¡µé¢æ˜¾ç¤º
                    st.session_state.df_result = final_df
                    st.session_state.csv_path = final_filename
                    status.update(label=T["status_complete"], state="complete", expanded=False)
                
            except Exception as e:
                status.update(label=T["status_failed"], state="error")
                st.error(f"An error occurred: {str(e)}")

# === 4. ç»“æœå±•ç¤ºåŒº ===
if st.session_state.df_result is not None:
    df = st.session_state.df_result
    
    st.divider()
    
    # æŒ‡æ ‡å¡ç‰‡
    col1, col2, col3 = st.columns(3)
    col1.metric(T["metrics_total"], len(df))
    
    # å°è¯•ç»Ÿè®¡éªŒè¯çŠ¶æ€
    if 'Data_Source' in df.columns:
        s2_count = len(df[df['Data_Source'] == 'S2_Verified'])
        web_count = len(df[df['Data_Source'] == 'Web_Bio'])
    else:
        s2_count = 0
        web_count = len(df)
        
    col2.metric(T["metrics_s2"], s2_count)
    col3.metric(T["metrics_web"], web_count)
    
    # æ•°æ®è¡¨
    st.subheader(T["data_preview"])
    st.dataframe(df, use_container_width=True)
    
    # ä¸‹è½½æŒ‰é’®
    if st.session_state.csv_path and os.path.exists(st.session_state.csv_path):
        with open(st.session_state.csv_path, "rb") as file:
            st.download_button(
                label=T["download_btn"],
                data=file,
                file_name=st.session_state.csv_path,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )